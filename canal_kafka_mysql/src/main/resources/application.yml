spring:
  application:
    name: iotGate

  redis:
    # 地址
    host: 212.64.64.158
    # 端口，默认为6379
    port: 6379
    # 数据库索引
    database: 10
    # 密码
    password: 1234567890
    # 连接超时时间
    timeout: 10s
    # 需要依赖包  commons-pool2
    lettuce:
      pool:
        # 连接池中的最小空闲连接
        min-idle: 0
        # 连接池中的最大空闲连接
        max-idle: 8
        # 连接池的最大数据库连接数
        max-active: 8
        # #连接池最大阻塞等待时间（使用负值表示没有限制）
        max-wait: -1ms

  kafka:
    bootstrap-servers: 114.115.163.35:9092
    # 消费者模式
    consumer:
      #      auto:
      #        commit:
      #          interval:
      #            # 提交offset延时(接收到消息后多久提交offset)
      #            ms: 1000
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      # 是否自动提交offset  这里配置true时需要配置auto.commit.interval.ms的时间
      enable-auto-commit: false
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 它表示最大的poll数据间隔，如果超过这个间隔没有发起pool请求，但heartbeat仍旧在发，就认为该consumer处于 livelock状态。就会将该consumer退出consumer group
      max-poll-records: 50
      # 默认的消费组ID
      properties:
        group:
          id: my_redis_con
        # 消费请求超时时间
        request:
          timeout:
            ms: 180000
        # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
        session:
          timeout:
            ms: 120000
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      listener:
        # 容器中的线程数，用于提高并发数量
        concurrency: 3
        # 消费端监听的topic不存在时，项目启动会报错(关掉)
        missing-topics-fatal: false
        # 设置批量消费
        type: batch
        #      public enum AckMode {
        #      // 当每一条记录被消费者监听器（ListenerConsumer）处理之后提交
        #      RECORD,
        #      // 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后提交
        #      BATCH,
        #      // 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，距离上次提交时间大于TIME时提交
        #      TIME,
        #      // 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后，被处理record数量大于等于COUNT时提交
        #      COUNT,
        #      // TIME |　COUNT　有一个条件满足时提交
        #      COUNT_TIME,
        #      // 当每一批poll()的数据被消费者监听器（ListenerConsumer）处理之后, 手动调用Acknowledgment.acknowledge()后提交
        #      MANUAL,
        #      // 手动调用Acknowledgment.acknowledge()后立即提交
        #      MANUAL_IMMEDIATE,
        #    }
        ack-mode: manual

    # 生产者模式
    ###########【初始化生产者配置】###########
    # 重试次数
    producer:
      retries: 0
      # 应答级别:多少个分区副本备份完成时向生产者发送ack确认(可选0、1、all/-1)
      acks: 1
      # 批量大小
      batch-size: 16384
      # 提交延时
      properties:
        linger:
          ms: 0
      # 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
      # linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
      # 生产端缓冲区大小
      buffer-memory: 33554432
      # Kafka提供的序列化和反序列化类
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 自定义分区器
    # spring.kafka.producer.properties.partitioner.class=com.felix.kafka.producer.CustomizePartitioner

canal:
  password: 4ACFE3202A5FF5CF467898FC58AAB1D615029441
  user-name: admin
  host: 47.94.220.29
  port: 11112
  destination: example #不填默认为example
  batchSize: 1000 #批次, 不填默认为1000
  filter: myblog.* #数据库,表过滤器,多个过滤器用逗号隔开 不填默认为全部数据库和表
  custom: true #true 为自定义表处理 , false为全局统一处理
